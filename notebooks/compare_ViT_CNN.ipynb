{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop\n",
    "from torchmetrics import AUROC\n",
    "from torch.utils.data import DataLoader\n",
    "from timm import models\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Modify Me according to your paths###\n",
    "ckpt_dir = \"checkpoints/\"\n",
    "ood_data_dir = \"data/OOD/\"\n",
    "id_data_dir = \"data/ID/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500 ID images and 500 OOD images\n",
    "target for ID images is 1 and target for OOD images is 0. (binary OOD detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamooler/anaconda3/envs/sem_proj/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori_preprocess = Compose([\n",
    "        Resize((224), interpolation=Image.BICUBIC),\n",
    "        CenterCrop(size=(224, 224)),\n",
    "        ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_images = []\n",
    "\n",
    "for folder in os.listdir(ood_data_dir):\n",
    "    for img_path in os.listdir(ood_data_dir+folder):\n",
    "        ood_images.append(Image.open(ood_data_dir+folder+\"/\"+img_path))\n",
    "\n",
    "ood_data = torch.zeros((len(ood_images), 3, 224, 224))\n",
    "ood_targets = torch.zeros(len(ood_data), dtype=torch.int)\n",
    "for ind, img in enumerate(ood_images):\n",
    "    image_tensor = ori_preprocess(img)\n",
    "    ood_data[ind] = image_tensor\n",
    "\n",
    "\n",
    "id_images = []\n",
    "\n",
    "for folder in os.listdir(id_data_dir):\n",
    "    for img_path in os.listdir(id_data_dir+folder):\n",
    "        id_images.append(Image.open(id_data_dir+folder+\"/\"+img_path))\n",
    "\n",
    "\n",
    "id_data = torch.zeros((len(id_images), 3, 224, 224))\n",
    "id_targets = torch.ones(len(id_data), dtype=torch.int)\n",
    "for ind, img in enumerate(id_images):\n",
    "    image_tensor = ori_preprocess(img)\n",
    "    id_data[ind] = image_tensor\n",
    "\n",
    "\n",
    "data = torch.cat((ood_data, id_data))\n",
    "targets = torch.cat((ood_targets, id_targets))\n",
    "\n",
    "# data = torchvision.datasets.CIFAR10(data_dir, download=True)\n",
    "# data_loader = DataLoader((data, target), batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamooler/anaconda3/envs/sem_proj/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "eval_metric = AUROC(num_classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamooler/anaconda3/envs/sem_proj/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-1wfnpb1e/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/tmp/ipykernel_20225/2131796798.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  res = self.softmax(res)\n"
     ]
    }
   ],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, model_ckpt):\n",
    "        super(ResNet, self).__init__()\n",
    "        resnet = models.resnet50()\n",
    "        ckpt = torch.load(f\"checkpoints/resnet50_a2_0-a2746f79.pth\")\n",
    "        resnet.load_state_dict(ckpt) \n",
    "        self.resnet = resnet\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, image):\n",
    "        res = self.resnet(image)\n",
    "        res = self.softmax(res)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "\n",
    "resnet = ResNet(f\"resnet50_a2_0-a2746f79.pth\")\n",
    "resnet_preds = resnet(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamooler/anaconda3/envs/sem_proj/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0008)\n"
     ]
    }
   ],
   "source": [
    "resnet_auroc = eval_metric(resnet_preds, targets)\n",
    "print(resnet_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mamooler/.cache/torch/hub/facebookresearch_deit_main\n"
     ]
    }
   ],
   "source": [
    "class DeiT(nn.Module):\n",
    "    def __init__(self, model_ckpt):\n",
    "        super(DeiT, self).__init__()\n",
    "        deit =  torch.hub.load('facebookresearch/deit:main', 'deit_small_patch16_224')\n",
    "        ckpt = torch.load(f\"checkpoints/deit_small_patch16_a2_0-83b53863.pth\")\n",
    "        deit.load_state_dict(ckpt) \n",
    "        self.deit = deit\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, image):\n",
    "        res = self.deit(image)\n",
    "        res = self.softmax(res)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "\n",
    "deit = DeiT(f\"deit_small_patch16_a2_0-83b53863.pth\")\n",
    "deit_preds = deit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Kernel is dead",
     "output_type": "error",
     "traceback": [
      "Error: Kernel is dead",
      "at g._sendKernelShellControl (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1006305)",
      "at g.sendShellMessage (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1006074)",
      "at g.requestExecute (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1008616)",
      "at d.requestExecute (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:37:328037)",
      "at S.requestExecute (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:32:19306)",
      "at w.executeCodeCell (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300924)",
      "at w.execute (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "deit_auroc = eval_metric(deit_preds, targets)\n",
    "print(deit_auroc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86954d66f957b711fa2e62420024fb7c77b94e3d0d510fdd3c6d5c0b60b14049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sem_proj': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
