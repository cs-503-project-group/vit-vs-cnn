{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop\n",
    "from torchmetrics import AUROC\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Modify Me according to your paths###\n",
    "ckpt_dir = \"/home/SHARED_FOLDER/checkpoints/\"\n",
    "ood_data_dir = \"/home/SHARED_FOLDER/data/OOD_data/\"\n",
    "id_data_dir = \"/home/SHARED_FOLDER/data/ID_data/imagenet1k-val/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500 ID images and 500 OOD images\n",
    "target for ID images is 1 and target for OOD images is 0. (binary OOD detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "ori_preprocess = Compose([\n",
    "        Resize((224), interpolation=Image.BICUBIC),\n",
    "        CenterCrop(size=(224, 224)),\n",
    "        ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Dataset(Dataset):\n",
    "    def __init__(self, id_data_dir, ood_data_dir):\n",
    "        self.id_data_dir = id_data_dir\n",
    "        self.ood_data_dir = ood_data_dir\n",
    "        self.data = []\n",
    "        for file in os.listdir(self.id_data_dir)[:1]:\n",
    "            self.data.append((self.id_data_dir+file, 0))\n",
    "        for file in os.listdir(self.ood_data_dir)[:1]:\n",
    "            self.data.append((self.ood_data_dir+file), 1)\n",
    "        print(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path, target = self.data[idx]\n",
    "        img = ori_preprocess(Image.open(img_path))\n",
    "\n",
    "        print(img)\n",
    "        print(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/home/SHARED_FOLDER/data/ID_data/imagenet1k-val/ILSVRC2010_val_00019553.JPEG', 0)]\n"
     ]
    }
   ],
   "source": [
    "dataset = Image_Dataset(id_data_dir, ood_data_dir)\n",
    "data_loader = DataLoader(dataset, batch_size = 1, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(model, dataloader, thresholds, device, num_classes=1000, batch_size=1):\n",
    "\n",
    "    probs = torch.zeros((batch_size, num_classes))\n",
    "    targets = torch.zeros((batch_size, 1))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # check value for threshold\n",
    "    prc = Precision(num_classes = num_classes, threshold=1)\n",
    "    with torch.no_grad():\n",
    "        for ind, input, batch_target in enumerate(dataloader):\n",
    "            input.to(device)\n",
    "            \n",
    "            batch_probs = model(input)\n",
    "            if ind==0:\n",
    "                probs = batch_probs\n",
    "                targets = batch_target\n",
    "            else:\n",
    "                # check\n",
    "                print(probs.size())\n",
    "                probs = torch.concat((probs, batch_probs), dim=1)\n",
    "                print(probs.size())\n",
    "                targets = torch.concat((targets, batch_target), dim=1)\n",
    "        \n",
    "    precisions = torch.zeros((len(thresholds),1))\n",
    "    for ind,t in enumerate(thresholds):\n",
    "        # check\n",
    "        preds = torch.max(probs, dim=1) < t\n",
    "        precision[ind] = prc(preds, targets)\n",
    "\n",
    "\n",
    "    return precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_threshold = 0.5\n",
    "resnet_model = resnet.ResNet(f\"{ckpt_dir}resnet50_a2_0-a2746f79.pth\", ood_threshold).to(device)\n",
    "# the goal is to identify OOD samples\n",
    "\n",
    "thresholds = torch.range(0.9, step=0.1)\n",
    "probs = torch.zeros((batch_size, num_classes))\n",
    "targets = torch.zeros((batch_size, 1))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "# check value for threshold\n",
    "# prc = Precision(num_classes = num_classes, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2725935056.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1579/2725935056.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    thresholds = torch.range(start 0.9, step=0.1)\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for ind, input_, batch_target in enumerate(dataloader):\n",
    "        input_.to(device)\n",
    "        batch_probs = model(input_)\n",
    "        if ind==0:\n",
    "            probs = batch_probs\n",
    "            targets = batch_target\n",
    "        else:\n",
    "            # check\n",
    "            print(probs.size())\n",
    "            probs = torch.concat((probs, batch_probs), dim=1)\n",
    "            print(probs.size())\n",
    "            targets = torch.concat((targets, batch_target), dim=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = torch.zeros((len(thresholds),1))\n",
    "\n",
    "for ind,t in enumerate(thresholds):\n",
    "    # check\n",
    "    preds = torch.max(probs, dim=1) < t\n",
    "    precision[ind] = prc(preds, targets)\n",
    "\n",
    "\n",
    "#resnet_precisions = precision(resnet_model, dataloader, thresholds, device)\n",
    "# tp = 0\n",
    "# resnet_preds = torch.zeros((8,1))\n",
    "# for data, target in dataloader:\n",
    "#     data.to(device)\n",
    "#     resnet_preds = resnet_model(data)\n",
    "    \n",
    "#     for i, pred in enumerate(resnet_preds):\n",
    "#         if pred == target[i]: tp+=1\n",
    "\n",
    "# precision = tp / len(dataset)\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamooler/anaconda3/envs/sem_proj/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0008)\n"
     ]
    }
   ],
   "source": [
    "resnet_auroc = eval_metric(resnet_preds, targets)\n",
    "print(resnet_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mamooler/.cache/torch/hub/facebookresearch_deit_main\n"
     ]
    }
   ],
   "source": [
    "deit_model = deit.DeiT(f\"deit_small_patch16_a2_0-83b53863.pth\")\n",
    "deit_preds = deit_model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Kernel is dead",
     "output_type": "error",
     "traceback": [
      "Error: Kernel is dead",
      "at g._sendKernelShellControl (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1006305)",
      "at g.sendShellMessage (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1006074)",
      "at g.requestExecute (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1008616)",
      "at d.requestExecute (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:37:328037)",
      "at S.requestExecute (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:32:19306)",
      "at w.executeCodeCell (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300924)",
      "at w.execute (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/home/mamooler/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "deit_auroc = eval_metric(deit_preds, targets)\n",
    "print(deit_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convmixer_model = convmixer.ConvMixer()\n",
    "convmixer_preds = convmixer_model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convMixer_auroc = eval_metric(convmixer_preds, targets)\n",
    "print(convMixer_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpmixer_model = mlpmixer.MLPMixer()\n",
    "mlpmixer_preds = mlpmixer_model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpmixer_auroc = eval_metric(mlpmixer_preds, targets)\n",
    "print(mlpmixer_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECA-ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecaresnet_model = ecaresnet.ECAResNet()\n",
    "ecaresnet_preds = ecaresnet_model.ecaresnet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecaresnet_auroc = eval_metric(ecaresnet_preds, targets)\n",
    "print(ecaresnet_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
