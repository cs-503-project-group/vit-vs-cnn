{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "from eval_utils import evaluate_OOD_detection, evaluate_ID_detection\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Modify Me according to your paths###\n",
    "# ckpt_dir = \"checkpoints/\"\n",
    "ood_data_dir = \"../data/OOD/\"\n",
    "id_data_dir = \"../data/ID/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500 ID images and 500 OOD images\n",
    "target for ID images is 1 and target for OOD images is 0. (binary OOD detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamooler/anaconda3/envs/sem_proj/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ori_preprocess = Compose([\n",
    "        Resize((224), interpolation=Image.BICUBIC),\n",
    "        CenterCrop(size=(224, 224)),\n",
    "        ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Image_Dataset(Dataset):\n",
    "    def __init__(self, id_data_dir, ood_data_dir):\n",
    "        self.id_data_dir = id_data_dir+\"acorn squash\"\n",
    "        self.ood_data_dir = ood_data_dir\n",
    "        self.data = []\n",
    "        for file in os.listdir(self.id_data_dir)[:10]:\n",
    "            self.data.append((self.id_data_dir+\"/\"+file, 0))\n",
    "        # for file in os.listdir(self.ood_data_dir)[:1]:\n",
    "        #     self.data.append((self.ood_data_dir+file, 1))\n",
    "        print(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path, target = self.data[idx]\n",
    "        img = ori_preprocess(Image.open(img_path))\n",
    "\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('../data/ID/acorn squash/295894360_57301e7f52.jpg', 0), ('../data/ID/acorn squash/3131799338_30cc952ab4.jpg', 0), ('../data/ID/acorn squash/2728402305_0423769588.jpg', 0), ('../data/ID/acorn squash/1481650104_cbe7276bb6.jpg', 0), ('../data/ID/acorn squash/3061250714_a132b0fc7e.jpg', 0), ('../data/ID/acorn squash/3219153054_5002a1d7a5.jpg', 0), ('../data/ID/acorn squash/2478437330_2a7d5626ae.jpg', 0), ('../data/ID/acorn squash/2982117320_133c332c66.jpg', 0), ('../data/ID/acorn squash/2758144776_ff013800b6.jpg', 0), ('../data/ID/acorn squash/2981258993_0542f8c00f.jpg', 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22323/1745201148.py:4: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  thresholds = torch.range(0.5, 0.9, step=0.1)\n"
     ]
    }
   ],
   "source": [
    "dataset = Image_Dataset(id_data_dir, ood_data_dir)\n",
    "data_loader = DataLoader(dataset, batch_size = 1, shuffle= True)\n",
    "\n",
    "thresholds = torch.range(0.5, 0.9, step=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamooler/anaconda3/envs/sem_proj/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-1wfnpb1e/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/mamooler/MA3/VisInt/vit-vs-cnn/notebooks/models/resnet.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = self.softmax(logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000]]) tensor([[0.6000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000]]) tensor([[0.6000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000]])\n"
     ]
    }
   ],
   "source": [
    "ood_threshold = 0.5\n",
    "resnet_model = resnet.ResNet().to(device)\n",
    "# the goal is to identify OOD samples\n",
    "\n",
    "resnet_prc, resnet_rec, resnet_f1 = evaluate_OOD_detection(resnet_model, data_loader, thresholds, device)\n",
    "print(resnet_prc, resnet_rec, resnet_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeiT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamooler/MA3/VisInt/vit-vs-cnn/notebooks/models/deit.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = self.softmax(logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6000],\n",
      "        [0.3000],\n",
      "        [0.2000],\n",
      "        [0.0000],\n",
      "        [0.0000]]) tensor([[0.6000],\n",
      "        [0.3000],\n",
      "        [0.2000],\n",
      "        [0.0000],\n",
      "        [0.0000]]) tensor([[0.6000],\n",
      "        [0.3000],\n",
      "        [0.2000],\n",
      "        [0.0000],\n",
      "        [0.0000]])\n"
     ]
    }
   ],
   "source": [
    "deit_model = deit.DeiT().to(device)\n",
    "\n",
    "deit_prc, deit_rec, deit_f1 = evaluate_OOD_detection(deit_model, data_loader, thresholds, device)\n",
    "print(deit_prc, deit_rec, deit_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convmixer_model = convmixer.ConvMixer().to(device)\n",
    "\n",
    "convmixer_prc, convmixer_rec, convmixer_f1 = evaluate_OOD_detection(convmixer_model, data_loader, thresholds, device)\n",
    "print(convmixer_prc, convmixer_rec, convmixer_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpmixer_model = mlpmixer.MLPMixer().to(device)\n",
    "\n",
    "mlpmixer_prc, mlpmixer_rec, mlpmixer_f1 = evaluate_OOD_detection(mlpmixer_model, data_loader, thresholds, device)\n",
    "print(mlpmixer_prc, mlpmixer_rec, mlpmixer_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECA-ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamooler/MA3/VisInt/vit-vs-cnn/notebooks/models/ecaresnet.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = self.softmax(logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7000],\n",
      "        [0.6000],\n",
      "        [0.4000],\n",
      "        [0.3000],\n",
      "        [0.0000]]) tensor([[0.7000],\n",
      "        [0.6000],\n",
      "        [0.4000],\n",
      "        [0.3000],\n",
      "        [0.0000]]) tensor([[0.7000],\n",
      "        [0.6000],\n",
      "        [0.4000],\n",
      "        [0.3000],\n",
      "        [0.0000]])\n"
     ]
    }
   ],
   "source": [
    "ecaresnet_model = ecaresnet.ECAResNet().to(device)\n",
    "ecaresnet_prc, ecaresnet_rec, ecaresnet_f1 = evaluate_OOD_detection(ecaresnet_model, data_loader, thresholds, device)\n",
    "print(ecaresnet_prc, ecaresnet_rec, ecaresnet_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86954d66f957b711fa2e62420024fb7c77b94e3d0d510fdd3c6d5c0b60b14049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sem_proj': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
